{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews = pd.read_csv(\"imdb_reviews.csv\")\n",
    "test_reviews = pd.read_csv(\"test_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;START this film was just brilliant casting lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;START big hair big boobs bad music and a gian...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;START this has to be one of the worst films o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;START the &lt;UNK&gt; &lt;UNK&gt; at storytelling the tra...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;START worst mistake of my life br br i picked...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment\n",
       "0  <START this film was just brilliant casting lo...  positive\n",
       "1  <START big hair big boobs bad music and a gian...  negative\n",
       "2  <START this has to be one of the worst films o...  negative\n",
       "3  <START the <UNK> <UNK> at storytelling the tra...  positive\n",
       "4  <START worst mistake of my life br br i picked...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file contain mapping of all the words to corresponding integers\n",
    "word_index = pd.read_csv(\"word_indexes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tsukino</td>\n",
       "      <td>52009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nunnery</td>\n",
       "      <td>52010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sonja</td>\n",
       "      <td>16819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vani</td>\n",
       "      <td>63954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woods</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spiders</td>\n",
       "      <td>16118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hanging</td>\n",
       "      <td>2348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>woody</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trawling</td>\n",
       "      <td>52011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hold's</td>\n",
       "      <td>52012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  Indexes\n",
       "0   tsukino    52009\n",
       "1   nunnery    52010\n",
       "2     sonja    16819\n",
       "3      vani    63954\n",
       "4     woods     1411\n",
       "5   spiders    16118\n",
       "6   hanging     2348\n",
       "7     woody     2292\n",
       "8  trawling    52011\n",
       "9    hold's    52012"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting dataframe to dictionary\n",
    "# words as keys and integers as values\n",
    "word_index = dict(zip(word_index.Words,word_index.Indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index[\"<PAD>\"]=0\n",
    "word_index[\"<START\"]=1\n",
    "word_index[\"<UNK>\"]=2\n",
    "word_index[\"<UNUSED>\"]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding reviews as integers\n",
    "def review_encoder(text):\n",
    "    arr=[word_index[word] for word in text]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the datasets\n",
    "train_data,train_labels = imdb_reviews['Reviews'],imdb_reviews['Sentiment']\n",
    "test_data,test_labels = test_reviews['Reviews'],test_reviews['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the strings on the bases of spaces\n",
    "train_data=train_data.apply(lambda review : review.split())\n",
    "test_data=test_data.apply(lambda review : review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START',\n",
       " 'this',\n",
       " 'film',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'casting',\n",
       " 'location',\n",
       " 'scenery',\n",
       " 'story',\n",
       " 'direction',\n",
       " \"everyone's\",\n",
       " 'really',\n",
       " 'suited',\n",
       " 'the',\n",
       " 'part',\n",
       " 'they',\n",
       " 'played',\n",
       " 'and',\n",
       " 'you',\n",
       " 'could',\n",
       " 'just',\n",
       " 'imagine',\n",
       " 'being',\n",
       " 'there',\n",
       " 'robert',\n",
       " '<UNK>',\n",
       " 'is',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'actor',\n",
       " 'and',\n",
       " 'now',\n",
       " 'the',\n",
       " 'same',\n",
       " 'being',\n",
       " 'director',\n",
       " '<UNK>',\n",
       " 'father',\n",
       " 'came',\n",
       " 'from',\n",
       " 'the',\n",
       " 'same',\n",
       " 'scottish',\n",
       " 'island',\n",
       " 'as',\n",
       " 'myself',\n",
       " 'so',\n",
       " 'i',\n",
       " 'loved',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'real',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'this',\n",
       " 'film',\n",
       " 'the',\n",
       " 'witty',\n",
       " 'remarks',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'film',\n",
       " 'were',\n",
       " 'great',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'film',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'it',\n",
       " 'was',\n",
       " 'released',\n",
       " 'for',\n",
       " '<UNK>',\n",
       " 'and',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'it',\n",
       " 'to',\n",
       " 'everyone',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fly',\n",
       " 'fishing',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'really',\n",
       " 'cried',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'sad',\n",
       " 'and',\n",
       " 'you',\n",
       " 'know',\n",
       " 'what',\n",
       " 'they',\n",
       " 'say',\n",
       " 'if',\n",
       " 'you',\n",
       " 'cry',\n",
       " 'at',\n",
       " 'a',\n",
       " 'film',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'good',\n",
       " 'and',\n",
       " 'this',\n",
       " 'definitely',\n",
       " 'was',\n",
       " 'also',\n",
       " '<UNK>',\n",
       " 'to',\n",
       " 'the',\n",
       " 'two',\n",
       " 'little',\n",
       " \"boy's\",\n",
       " 'that',\n",
       " 'played',\n",
       " 'the',\n",
       " '<UNK>',\n",
       " 'of',\n",
       " 'norman',\n",
       " 'and',\n",
       " 'paul',\n",
       " 'they',\n",
       " 'were',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'children',\n",
       " 'are',\n",
       " 'often',\n",
       " 'left',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " '<UNK>',\n",
       " 'list',\n",
       " 'i',\n",
       " 'think',\n",
       " 'because',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'that',\n",
       " 'play',\n",
       " 'them',\n",
       " 'all',\n",
       " 'grown',\n",
       " 'up',\n",
       " 'are',\n",
       " 'such',\n",
       " 'a',\n",
       " 'big',\n",
       " 'profile',\n",
       " 'for',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'film',\n",
       " 'but',\n",
       " 'these',\n",
       " 'children',\n",
       " 'are',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'should',\n",
       " 'be',\n",
       " 'praised',\n",
       " 'for',\n",
       " 'what',\n",
       " 'they',\n",
       " 'have',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'you',\n",
       " 'think',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'story',\n",
       " 'was',\n",
       " 'so',\n",
       " 'lovely',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'true',\n",
       " 'and',\n",
       " 'was',\n",
       " \"someone's\",\n",
       " 'life',\n",
       " 'after',\n",
       " 'all',\n",
       " 'that',\n",
       " 'was',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding this data as integers\n",
    "train_data = train_data.apply(review_encoder)\n",
    "test_data = test_data.apply(review_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentiments(sentiment):\n",
    "    if sentiment=='positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_labels = train_labels.apply(encode_sentiments)\n",
    "test_labels = test_labels.apply(encode_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding to make all reviews of equal size\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,value=word_index[\"<PAD>\"],padding='post',maxlen=500)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,value=word_index[\"<PAD>\"],padding='post',maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding will convert each word into length of 16\n",
    "# and each review into length of 500\n",
    "model=keras.Sequential([keras.layers.Embedding(10000,16,input_length=500),\n",
    "                       keras.layers.GlobalAveragePooling1D(),\n",
    "                       keras.layers.Dense(16,activation='relu'),\n",
    "                       keras.layers.Dense(1,activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "49/49 [==============================] - 7s 55ms/step - loss: 0.6915 - accuracy: 0.5502 - val_loss: 0.6891 - val_accuracy: 0.6560\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.6828 - accuracy: 0.6959 - val_loss: 0.6757 - val_accuracy: 0.7170\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.6599 - accuracy: 0.7346 - val_loss: 0.6464 - val_accuracy: 0.7489\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 3s 64ms/step - loss: 0.6189 - accuracy: 0.7742 - val_loss: 0.6012 - val_accuracy: 0.7881\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 3s 60ms/step - loss: 0.5647 - accuracy: 0.8113 - val_loss: 0.5488 - val_accuracy: 0.8082\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.5047 - accuracy: 0.8366 - val_loss: 0.4948 - val_accuracy: 0.8292\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 0.4488 - accuracy: 0.8546 - val_loss: 0.4486 - val_accuracy: 0.8436\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 3s 59ms/step - loss: 0.4016 - accuracy: 0.8688 - val_loss: 0.4125 - val_accuracy: 0.8534\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 3s 58ms/step - loss: 0.3635 - accuracy: 0.8797 - val_loss: 0.3831 - val_accuracy: 0.8606\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 3s 54ms/step - loss: 0.3334 - accuracy: 0.8880 - val_loss: 0.3613 - val_accuracy: 0.8662\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.3096 - accuracy: 0.8928 - val_loss: 0.3446 - val_accuracy: 0.8705\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.2898 - accuracy: 0.9003 - val_loss: 0.3334 - val_accuracy: 0.8715\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.2737 - accuracy: 0.9053 - val_loss: 0.3215 - val_accuracy: 0.8760\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.2589 - accuracy: 0.9094 - val_loss: 0.3139 - val_accuracy: 0.8773\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2467 - accuracy: 0.9143 - val_loss: 0.3066 - val_accuracy: 0.8792\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.2355 - accuracy: 0.9185 - val_loss: 0.3008 - val_accuracy: 0.8820\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.2254 - accuracy: 0.9221 - val_loss: 0.2971 - val_accuracy: 0.8824\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2164 - accuracy: 0.9256 - val_loss: 0.2946 - val_accuracy: 0.8823\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.2089 - accuracy: 0.9277 - val_loss: 0.2932 - val_accuracy: 0.8834\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2005 - accuracy: 0.9316 - val_loss: 0.2885 - val_accuracy: 0.8851\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1938 - accuracy: 0.9340 - val_loss: 0.2868 - val_accuracy: 0.8857\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.1874 - accuracy: 0.9370 - val_loss: 0.2857 - val_accuracy: 0.8865\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.1809 - accuracy: 0.9382 - val_loss: 0.2861 - val_accuracy: 0.8861\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 0.1750 - accuracy: 0.9414 - val_loss: 0.2858 - val_accuracy: 0.8859\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1698 - accuracy: 0.9436 - val_loss: 0.2860 - val_accuracy: 0.8865\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1650 - accuracy: 0.9438 - val_loss: 0.2881 - val_accuracy: 0.8856\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1604 - accuracy: 0.9457 - val_loss: 0.2874 - val_accuracy: 0.8850\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.1563 - accuracy: 0.9477 - val_loss: 0.2880 - val_accuracy: 0.8861\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.1509 - accuracy: 0.9505 - val_loss: 0.2891 - val_accuracy: 0.8860\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 0.1472 - accuracy: 0.9512 - val_loss: 0.2909 - val_accuracy: 0.8851\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data,train_labels,epochs=30,batch_size=512,validation_data=(test_data,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 2ms/step - loss: 0.2909 - accuracy: 0.8851\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;START please give this one a miss br br &lt;UNK&gt;...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;START this film requires a lot of patience be...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;START many animation buffs consider &lt;UNK&gt; &lt;UN...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;START i generally love this type of movie how...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;START like some other people wrote i'm a die ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment\n",
       "0  <START please give this one a miss br br <UNK>...  negative\n",
       "1  <START this film requires a lot of patience be...  positive\n",
       "2  <START many animation buffs consider <UNK> <UN...  positive\n",
       "3  <START i generally love this type of movie how...  negative\n",
       "4  <START like some other people wrote i'm a die ...  positive"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews      <START this movie was a failure as a comedy an...\n",
      "Sentiment                                             negative\n",
      "Name: 431, dtype: object\n"
     ]
    }
   ],
   "source": [
    "user_review = test_reviews.loc[idx]\n",
    "print(user_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative sentiment\n"
     ]
    }
   ],
   "source": [
    "user_review = test_data[idx]\n",
    "user_review = np.array([user_review])\n",
    "if(model.predict(user_review) > 0.5).astype(\"int32\"):\n",
    "    print(\"positive sentiment\")\n",
    "else:\n",
    "    print(\"negative sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
